# Annotation Pipeline Summary

This document summarizes the annotation pipeline tools created to help you go from 36 PNG files to a trained ONNX model.

## ğŸ¯ What Was Created

### 1. Setup Scripts

**`scripts/setup-annotation-workflow.ps1`**
- Prepares directory structure for annotation
- Checks existing annotations
- Provides instructions for annotation tools
- Creates helper script to launch LabelImg

**Usage:**
```powershell
pwsh scripts/setup-annotation-workflow.ps1
```

### 2. Validation Scripts

**`scripts/validate-yolo-annotations.ps1`**
- Validates YOLO format annotations
- Checks format correctness (5 values per line)
- Verifies values are in valid range (0-1)
- Ensures bounding boxes don't extend outside image

**Usage:**
```powershell
pwsh scripts/validate-yolo-annotations.ps1
```

### 3. Master Pipeline Script

**`scripts/complete-annotation-pipeline.ps1`**
- Orchestrates the entire workflow:
  1. Verifies original annotations (36 files)
  2. Processes images (rotate, black background) - optional
  3. Transforms annotations for rotations
  4. Copies annotations for black background
  5. Merges annotations for final dataset
  6. Verifies annotations
  7. Splits dataset (train/val/test)
  8. Trains YOLO model
  9. Exports to ONNX format

**Usage:**
```powershell
# Full pipeline (with training)
pwsh scripts/complete-annotation-pipeline.ps1

# Skip image processing (use existing)
pwsh scripts/complete-annotation-pipeline.ps1 -SkipProcessing

# Skip training (just process annotations)
pwsh scripts/complete-annotation-pipeline.ps1 -SkipTraining
```

### 4. Updated Scripts

**`scripts/split-dataset.ps1`** (Updated)
- Now copies labels along with images
- Automatically detects if labels exist
- Creates label directories for train/val/test

### 5. Documentation

**`ANNOTATION_PIPELINE_QUICK_START.md`**
- Complete step-by-step guide
- Annotation tool options (LabelImg, Roboflow, AI pre-annotation)
- Troubleshooting guide
- YOLO format reference

---

## ğŸ“‹ Workflow Overview

```
36 PNG Files (data/raw/RobotFloor/)
    â†“
[Annotate in YOLO format]
    â†“
36 Annotation Files (data/raw/RobotFloor/labels/)
    â†“
[Run Pipeline]
    â†“
Process Images:
  - Rotate (23 angles)
  - Black background
  - Compress
    â†“
Transform Annotations:
  - Rotate coordinates for rotated images
  - Copy for black background versions
  - Merge for final dataset
    â†“
1,824 Images + Annotations (data/processed/RobotFloor/)
    â†“
Split Dataset:
  - 70% Training (~1,277)
  - 20% Validation (~365)
  - 10% Test (~182)
    â†“
Train YOLO Model:
  - Train on dataset
  - Export to ONNX
    â†“
ONNX Model (models/onnx/robot_detection.onnx)
```

---

## ğŸš€ Quick Start

### Step 1: Setup
```powershell
pwsh scripts/setup-annotation-workflow.ps1
```

### Step 2: Annotate
Use LabelImg, Roboflow, or AI pre-annotation to annotate 36 PNG files.

### Step 3: Validate
```powershell
pwsh scripts/validate-yolo-annotations.ps1
```

### Step 4: Run Pipeline
```powershell
pwsh scripts/complete-annotation-pipeline.ps1
```

That's it! The pipeline handles everything automatically.

---

## ğŸ“ File Structure

After running the pipeline:

```
data/
â”œâ”€â”€ raw/
â”‚   â””â”€â”€ RobotFloor/
â”‚       â”œâ”€â”€ Robotfloor1.png ... Robotfloor36.png
â”‚       â””â”€â”€ labels/
â”‚           â””â”€â”€ Robotfloor1.txt ... Robotfloor36.txt
â”œâ”€â”€ processed/
â”‚   â””â”€â”€ RobotFloor/
â”‚       â”œâ”€â”€ [1824 processed images]
â”‚       â””â”€â”€ labels/
â”‚           â””â”€â”€ [1824 annotation files]
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ images/ [~1277]
â”‚   â””â”€â”€ labels/ [~1277]
â”œâ”€â”€ validation/
â”‚   â”œâ”€â”€ images/ [~365]
â”‚   â””â”€â”€ labels/ [~365]
â””â”€â”€ test/
    â”œâ”€â”€ images/ [~182]
    â””â”€â”€ labels/ [~182]

models/
â””â”€â”€ onnx/
    â””â”€â”€ robot_detection.onnx
```

---

## âœ… Key Features

1. **Smart Annotation Workflow**
   - Only annotate 36 original files
   - Automatic transformation for rotated images
   - Automatic copying for black background versions
   - Saves 16-26 hours vs manual annotation

2. **Robust Validation**
   - Format validation
   - Range checking
   - Bounding box validation
   - Catches errors before training

3. **Complete Automation**
   - Single command runs entire pipeline
   - Handles all annotation transformations
   - Automatic dataset splitting
   - Training and ONNX export

4. **Flexible Options**
   - Skip image processing if already done
   - Skip training if just processing annotations
   - Step-by-step execution available

---

## ğŸ”§ Script Details

### Annotation Transformation

The pipeline automatically handles:
- **Rotation transformation**: Rotates bounding box coordinates when images are rotated
- **Black background copying**: Copies annotations (same content, just background changed)
- **Merging**: Combines annotations from different sources into final dataset

### Coordinate Transformation

When rotating images:
- Original: 640x640 pixels
- Rotated: Larger canvas (e.g., 905x905 for 45Â°)
- Bounding boxes are automatically transformed
- Coordinates normalized to new image dimensions

---

## ğŸ“š Related Documentation

- `ANNOTATION_PIPELINE_QUICK_START.md` - Step-by-step guide
- `docs/ANNOTATION_EXPLAINED.md` - What is annotation?
- `docs/TRAINING_GUIDE.md` - Training details
- `docs/ONNX_COMPLETE_GUIDE.md` - ONNX workflow
- `docs/SMART_ANNOTATION_WORKFLOW.md` - Smart annotation strategy

---

## ğŸ†˜ Troubleshooting

### Scripts not found
- Make sure you're in the project root directory
- Use `pwsh` (PowerShell 7) not `powershell`

### Annotation validation fails
- Check format: `class_id center_x center_y width height`
- All values except class_id must be 0.0 to 1.0
- Run: `pwsh scripts/validate-yolo-annotations.ps1`

### Pipeline fails
- Check prerequisites are installed
- Verify annotations exist in `data/raw/RobotFloor/labels/`
- Review error messages for specific issues

---

## ğŸ‰ Success!

After completing the pipeline, you'll have:
- âœ… 1,824 processed images with annotations
- âœ… Dataset split into train/val/test
- âœ… Trained YOLO model
- âœ… ONNX model ready for C# application

**Next step:** Test the model in your C# application!

